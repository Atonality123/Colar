{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\asus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (2.0.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\asus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.20.3 in c:\\users\\asus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas) (1.23.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\asus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\asus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.2.1\n",
      "[notice] To update, run: C:\\Users\\ASUS\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of values where the 'id' column has the same part of the name and the 'time' column is the same:\n",
      "id_group  time                     \n",
      "fl1       2022-12-25 23:00:00+08:00    523.709\n",
      "          2022-12-25 23:01:00+08:00    522.840\n",
      "          2022-12-25 23:02:00+08:00    533.235\n",
      "          2022-12-25 23:03:00+08:00    362.062\n",
      "          2022-12-25 23:04:00+08:00    379.917\n",
      "                                        ...   \n",
      "fl9       2022-12-25 23:55:00+08:00    121.686\n",
      "          2022-12-25 23:56:00+08:00    148.758\n",
      "          2022-12-25 23:57:00+08:00    149.933\n",
      "          2022-12-25 23:58:00+08:00    151.548\n",
      "          2022-12-25 23:59:00+08:00    143.486\n",
      "Name: value, Length: 780, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#ไฟล์เดียว\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Read 1/4 of the files\n",
    "df = pd.read_csv(r\"E:\\CUSC Datalake\\witya\\witya-2022-12-25T2300.csv\")\n",
    "\n",
    "# Filter rows where \"id\" column contains \"multi_sensor\"\n",
    "df = df[df['id'].str.contains('emu_mc|emu_sm')]\n",
    "\n",
    "# Use tqdm to create a progress bar for Step 1\n",
    "df = df[df['value'].apply(pd.to_numeric, errors='coerce').notna()]\n",
    "\n",
    "# Use tqdm to create a progress bar for Step 2\n",
    "df['value'] = df['value'].astype(float)\n",
    "\n",
    "# Use tqdm to create a progress bar for Step 3\n",
    "df = df[df['value'] >= 0]\n",
    "\n",
    "# Use tqdm to create a progress bar for Step 4\n",
    "df['time'] = pd.to_datetime(df['time'], format='ISO8601', errors='coerce')\n",
    "\n",
    "# Use tqdm to create a progress bar for Step 6\n",
    "df['id_group'] = df['id'].str.extract(r'(fl(?:m|\\d{1,2}[a-zA-Z]?))')\n",
    "sum_by_id_time = df.groupby(['id_group', 'time'])['value'].sum()\n",
    "\n",
    "# Display the result\n",
    "print(\"Sum of values where the 'id' column has the same part of the name and the 'time' column is the same:\")\n",
    "print(sum_by_id_time)\n",
    "\n",
    "# Export the result to a CSV file\n",
    "sum_by_id_time.to_csv('E:\\\\Sort Data\\\\cham4 sorted.csv', index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading files: 100%|██████████| 732/732 [00:58<00:00, 12.57file/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of values where the 'id' column has the same part of the name and the 'time' column is the same:\n",
      "id_floor  time                     \n",
      "fl1       2022-09-10 09:00:00+08:00     2.525\n",
      "          2022-09-10 09:01:00+08:00     2.592\n",
      "          2022-09-10 09:02:00+08:00     2.553\n",
      "          2022-09-10 09:03:00+08:00     4.292\n",
      "          2022-09-10 09:04:00+08:00    12.456\n",
      "                                        ...  \n",
      "fl7       2022-12-31 23:55:00+08:00    60.444\n",
      "          2022-12-31 23:56:00+08:00    60.462\n",
      "          2022-12-31 23:57:00+08:00    60.355\n",
      "          2022-12-31 23:58:00+08:00    55.183\n",
      "          2022-12-31 23:59:00+08:00    53.679\n",
      "Name: value, Length: 282315, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#โฟลเดอร์\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def read_files_in_fraction(directory_path, fraction_start, fraction_end):\n",
    "    # Get a list of file names in the directory\n",
    "    file_names = os.listdir(directory_path)\n",
    "\n",
    "    # Calculate the number of files to read based on the fraction\n",
    "    num_files_to_read_start = int(len(file_names) * fraction_start)\n",
    "    num_files_to_read_end = int(len(file_names) * fraction_end)\n",
    "\n",
    "    # Initialize an empty list to store individual DataFrames\n",
    "    dataframes = []\n",
    "\n",
    "    # Use tqdm to create a progress bar for reading files\n",
    "    for file_name in tqdm(file_names[num_files_to_read_start:num_files_to_read_end], desc=\"Reading files\", unit=\"file\"):\n",
    "        if file_name.endswith('.csv'):  # Adjust the file extension based on your files (e.g., .csv, .xlsx, etc.)\n",
    "            file_path = os.path.join(directory_path, file_name)\n",
    "            df2 = pd.read_csv(file_path)  # Replace 'read_csv' with 'read_excel' for Excel files\n",
    "            dataframes.append(df2)\n",
    "\n",
    "    # Concatenate all the individual DataFrames into a single DataFrame\n",
    "    df3 = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "    return df3\n",
    "\n",
    "# Replace 'directory_path' with the path to the directory containing your files\n",
    "directory_path = 'E:\\\\CUSC Datalake\\\\cham4'\n",
    "\n",
    "# Read 1/4 of the files\n",
    "df = read_files_in_fraction(directory_path, 0.75, 1)\n",
    "\n",
    "# Filter rows where \"id\" column contains \"multi_sensor\"\n",
    "df = df[df['id'].str.contains('/wh')]\n",
    "\n",
    "# Use tqdm to create a progress bar for Step 1\n",
    "df = df[df['value'].apply(pd.to_numeric, errors='coerce').notna()]\n",
    "\n",
    "# Use tqdm to create a progress bar for Step 2\n",
    "df['value'] = df['value'].astype(float)\n",
    "\n",
    "# Use tqdm to create a progress bar for Step 3\n",
    "df = df[df['value'] >= 0]\n",
    "\n",
    "# Use tqdm to create a progress bar for Step 4\n",
    "df['time'] = pd.to_datetime(df['time'], format='ISO8601', errors='coerce')\n",
    "\n",
    "# Use tqdm to create a progress bar for Step 6\n",
    "df['id_floor'] = df['id'].str.extract(r'(fl(?:m|\\d{1,2}[a-zA-Z]?))')\n",
    "sum_by_id_time = df.groupby(['id_floor', 'time'])['value'].sum()\n",
    "\n",
    "# Display the result\n",
    "print(\"Sum of values where the 'id' column has the same part of the name and the 'time' column is the same:\")\n",
    "print(sum_by_id_time)\n",
    "\n",
    "# Export the result to a CSV file\n",
    "sum_by_id_time.to_csv(r'E:\\Sort Data\\cham4_energy\\cham4_energy_4.csv', index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading files: 100%|██████████| 732/732 [00:43<00:00, 16.64file/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of values where the 'id' column has the same part of the name and the 'time' column is the same:\n",
      "id_floor  time                     \n",
      "fl1       2022-09-10 09:00:00+08:00     2.525\n",
      "          2022-09-10 09:01:00+08:00     2.592\n",
      "          2022-09-10 09:02:00+08:00     2.553\n",
      "          2022-09-10 09:03:00+08:00     4.292\n",
      "          2022-09-10 09:04:00+08:00    12.456\n",
      "                                        ...  \n",
      "fl7       2022-12-31 23:55:00+08:00    60.444\n",
      "          2022-12-31 23:56:00+08:00    60.462\n",
      "          2022-12-31 23:57:00+08:00    60.355\n",
      "          2022-12-31 23:58:00+08:00    55.183\n",
      "          2022-12-31 23:59:00+08:00    53.679\n",
      "Name: value, Length: 282330, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#โฟลเดอร์\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def read_files_in_fraction(directory_path, fraction_start, fraction_end):\n",
    "    # Get a list of file names in the directory\n",
    "    file_names = os.listdir(directory_path)\n",
    "\n",
    "    # Calculate the number of files to read based on the fraction\n",
    "    num_files_to_read_start = int(len(file_names) * fraction_start)\n",
    "    num_files_to_read_end = int(len(file_names) * fraction_end)\n",
    "\n",
    "    # Initialize an empty list to store individual DataFrames\n",
    "    dataframes = []\n",
    "\n",
    "    # Use tqdm to create a progress bar for reading files\n",
    "    for file_name in tqdm(file_names[num_files_to_read_start:num_files_to_read_end], desc=\"Reading files\", unit=\"file\"):\n",
    "        if file_name.endswith('.csv'):  # Adjust the file extension based on your files (e.g., .csv, .xlsx, etc.)\n",
    "            file_path = os.path.join(directory_path, file_name)\n",
    "            df2 = pd.read_csv(file_path)  # Replace 'read_csv' with 'read_excel' for Excel files\n",
    "            dataframes.append(df2)\n",
    "\n",
    "    # Concatenate all the individual DataFrames into a single DataFrame\n",
    "    df3 = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "    return df3\n",
    "\n",
    "# Replace 'directory_path' with the path to the directory containing your files\n",
    "directory_path = 'E:\\\\CUSC Datalake\\\\cham4'\n",
    "\n",
    "# Read 1/4 of the files\n",
    "df = read_files_in_fraction(directory_path, 0.75, 1)\n",
    "\n",
    "# Filter rows where \"id\" column contains \"multi_sensor\"\n",
    "df = df[df['id'].str.contains('emu_mc|emu_sm')]\n",
    "\n",
    "# Use tqdm to create a progress bar for Step 1\n",
    "df = df[df['value'].apply(pd.to_numeric, errors='coerce').notna()]\n",
    "\n",
    "# Use tqdm to create a progress bar for Step 2\n",
    "df['value'] = df['value'].astype(float)\n",
    "\n",
    "# Use tqdm to create a progress bar for Step 3\n",
    "df = df[df['value'] >= 0]\n",
    "\n",
    "# Use tqdm to create a progress bar for Step 4\n",
    "df['time'] = pd.to_datetime(df['time'], format='ISO8601', errors='coerce')\n",
    "\n",
    "# Use tqdm to create a progress bar for Step 6\n",
    "df['id_floor'] = df['id'].str.extract(r'(fl(?:m|\\d{1,2}[a-zA-Z]?))')\n",
    "sum_by_id_time = df.groupby(['id_floor', 'time'])['value'].sum()\n",
    "\n",
    "# Display the result\n",
    "print(\"Sum of values where the 'id' column has the same part of the name and the 'time' column is the same:\")\n",
    "print(sum_by_id_time)\n",
    "\n",
    "# Export the result to a CSV file\n",
    "sum_by_id_time.to_csv(r'E:\\Sort Data\\cham4_energy\\cham4_energy_test4.csv', index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id_floor                      time   value  temperature  humidity  \\\n",
      "0           fl1 2022-09-10 09:00:00+08:00   2.525        28.90     85.33   \n",
      "13          fl1 2022-09-10 09:01:00+08:00   2.592        28.90     85.33   \n",
      "20          fl1 2022-09-10 09:02:00+08:00   2.553        28.90     85.33   \n",
      "27          fl1 2022-09-10 09:03:00+08:00   4.292        28.90     85.33   \n",
      "29          fl1 2022-09-10 09:04:00+08:00  12.456        28.90     85.40   \n",
      "...         ...                       ...     ...          ...       ...   \n",
      "282282      fl7 2022-12-31 23:55:00+08:00  60.444        29.41     53.69   \n",
      "282290      fl7 2022-12-31 23:56:00+08:00  60.462        29.89     50.75   \n",
      "282300      fl7 2022-12-31 23:57:00+08:00  60.355        29.89     50.75   \n",
      "282306      fl7 2022-12-31 23:58:00+08:00  55.183        29.51     49.74   \n",
      "282314      fl7 2022-12-31 23:59:00+08:00  53.679        29.28     54.44   \n",
      "\n",
      "        intensity  \n",
      "0             0.0  \n",
      "13            0.0  \n",
      "20            0.0  \n",
      "27            0.0  \n",
      "29            0.0  \n",
      "...           ...  \n",
      "282282        0.0  \n",
      "282290        0.0  \n",
      "282300        0.0  \n",
      "282306        0.0  \n",
      "282314        0.0  \n",
      "\n",
      "[282315 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "#merge new energy\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def read_files_in_fraction(directory_path, fraction_start, fraction_end):\n",
    "    # Get a list of file names in the directory\n",
    "    file_names = os.listdir(directory_path)\n",
    "\n",
    "    # Calculate the number of files to read based on the fraction\n",
    "    num_files_to_read_start = int(len(file_names) * fraction_start)\n",
    "    num_files_to_read_end = int(len(file_names) * fraction_end)\n",
    "\n",
    "    # Initialize an empty list to store individual DataFrames\n",
    "    dataframes = []\n",
    "\n",
    "    # Use tqdm to create a progress bar for reading files\n",
    "    for file_name in tqdm(file_names[num_files_to_read_start:num_files_to_read_end], desc=\"Reading files\", unit=\"file\"):\n",
    "        if file_name.endswith('.csv'):  # Adjust the file extension based on your files (e.g., .csv, .xlsx, etc.)\n",
    "            file_path = os.path.join(directory_path, file_name)\n",
    "            df2 = pd.read_csv(file_path)  # Replace 'read_csv' with 'read_excel' for Excel files\n",
    "            dataframes.append(df2)\n",
    "\n",
    "    # Concatenate all the individual DataFrames into a single DataFrame\n",
    "    df3 = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "    return df3\n",
    "\n",
    "# Replace 'directory_path' with the path to the directory containing your files\n",
    "directory_path = 'E:\\\\CUSC Datalake\\\\cham4' #<<<<<<<<<<<< folder energy\n",
    "\n",
    "# Read 1/4 of the files\n",
    "df1 = read_files_in_fraction(directory_path, 0, 1)\n",
    "\n",
    "df2 = pd.read_csv(r\"E:\\Sort Data\\cham4_mix\\cham4_4variable_4.csv\")  #<<<<<<<<<<<<<< file 4 variable\n",
    "\n",
    "# Convert 'time' columns to datetime objects for both DataFrames\n",
    "df1['time'] = pd.to_datetime(df1['time'])\n",
    "df2['time'] = pd.to_datetime(df2['time'])\n",
    "\n",
    "#rename\n",
    "df1.rename(columns={'value': 'energy'}, inplace=True)\n",
    "\n",
    "# Remove the 'id' column\n",
    "df2.drop('energy', axis=1, inplace=True)\n",
    "\n",
    "# Sort both DataFrames by 'time'\n",
    "df1 = df1.sort_values(by='time')\n",
    "df2 = df2.sort_values(by='time')\n",
    "\n",
    "# Merge the two DataFrames based on 'time' and 'id_floor' using merge_asof\n",
    "result = pd.merge_asof(df1, df2, on='time', by='id_floor', direction='forward', tolerance=pd.Timedelta('5 minutes'))\n",
    "\n",
    "#sort\n",
    "result = result.sort_values(by=['id_floor','time'])\n",
    "\n",
    "print(result)\n",
    "\n",
    "result.to_csv(r\"E:\\Sort Data\\cham4_mix\\cham4_4variable_4.csv\", index=False)  #<<<<<<<<<<<<<<"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
