{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading files:   0%|          | 0/732 [00:00<?, ?file/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading files: 100%|██████████| 732/732 [00:54<00:00, 13.35file/s]\n"
     ]
    }
   ],
   "source": [
    "#โฟลเดอร์\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def read_files_in_fraction(directory_path, fraction_start, fraction_end):\n",
    "    # Get a list of file names in the directory\n",
    "    file_names = os.listdir(directory_path)\n",
    "\n",
    "    # Calculate the number of files to read based on the fraction\n",
    "    num_files_to_read_start = int(len(file_names) * fraction_start)\n",
    "    num_files_to_read_end = int(len(file_names) * fraction_end)\n",
    "\n",
    "    # Initialize an empty list to store individual DataFrames\n",
    "    dataframes = []\n",
    "\n",
    "    # Use tqdm to create a progress bar for reading files\n",
    "    for file_name in tqdm(file_names[num_files_to_read_start:num_files_to_read_end], desc=\"Reading files\", unit=\"file\"):\n",
    "        if file_name.endswith('.csv'):  # Adjust the file extension based on your files (e.g., .csv, .xlsx, etc.)\n",
    "            file_path = os.path.join(directory_path, file_name)\n",
    "            df2 = pd.read_csv(file_path)  # Replace 'read_csv' with 'read_excel' for Excel files\n",
    "            dataframes.append(df2)\n",
    "\n",
    "    # Concatenate all the individual DataFrames into a single DataFrame\n",
    "    df3 = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "    return df3\n",
    "\n",
    "# Replace 'directory_path' with the path to the directory containing your files\n",
    "directory_path = 'E:\\\\CUSC Datalake\\\\cham4'  #<<<<<<<<<<<<<\n",
    "\n",
    "# Read 1/4 of the files\n",
    "df = read_files_in_fraction(directory_path, 0, 0.25)  #<<<<<<<<<<<<<\n",
    "\n",
    "file_save_name = r\"E:\\Sort Data\\cham4_intensity\\cham4_intensity_test.csv\"  #<<<<<<<<<<<<<\n",
    "\n",
    "# Filter rows where \"id\" column contains \"multi_sensor\"\n",
    "df = df[df['id'].str.contains('intensity')]\n",
    "\n",
    "# Convert 'value' column to numeric (float) type if it's not already done\n",
    "df['value'] = pd.to_numeric(df['value'], errors='coerce')\n",
    "\n",
    "#extract id_floor\n",
    "df['id_floor'] = df['id'].str.extract(r'(fl(?:m|\\d{1,2}[a-zA-Z]?))')\n",
    "\n",
    "#sort\n",
    "df = df.sort_values(by=['id_floor','time']) \n",
    "\n",
    "# Remove the 'id' column\n",
    "#df = df.drop('id', axis=1)\n",
    "\n",
    "# Convert 'time' column to pandas datetime object\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "\n",
    "# Round the minute to the nearest minute\n",
    "df['time'] = df['time'].dt.round('1min')\n",
    "\n",
    "# Group by 'time' and calculate the average temperature for each unique timestamp\n",
    "# df['value'] = df.groupby(['id_floor', 'time'])['value'].transform('mean')\n",
    "\n",
    "# Format the 'value' column to two decimal places\n",
    "# df['value'] = df['value'].round(2)\n",
    "\n",
    "# Drop rows with the same time\n",
    "# df = df.drop_duplicates(subset=['time', 'id_floor'], keep='first')\n",
    "\n",
    "# rename\n",
    "df.rename(columns={'value': 'intensity'}, inplace=True)\n",
    "\n",
    "df.to_csv(file_save_name, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id_floor                      time  energy  temperature  humidity  \\\n",
      "0           fl1 2022-09-10 09:00:00+08:00   2.525        28.90     85.33   \n",
      "12          fl1 2022-09-10 09:01:00+08:00   2.592        28.90     85.33   \n",
      "15          fl1 2022-09-10 09:02:00+08:00   2.553        28.90     85.33   \n",
      "22          fl1 2022-09-10 09:03:00+08:00   4.292        28.90     85.33   \n",
      "30          fl1 2022-09-10 09:04:00+08:00  12.456        28.90     85.40   \n",
      "...         ...                       ...     ...          ...       ...   \n",
      "282284      fl7 2022-12-31 23:55:00+08:00  60.444        29.41     53.69   \n",
      "282292      fl7 2022-12-31 23:56:00+08:00  60.462        29.89     50.75   \n",
      "282302      fl7 2022-12-31 23:57:00+08:00  60.355        29.89     50.75   \n",
      "282308      fl7 2022-12-31 23:58:00+08:00  55.183        29.51     49.74   \n",
      "282316      fl7 2022-12-31 23:59:00+08:00  53.679        29.28     54.44   \n",
      "\n",
      "        intensity  \n",
      "0             0.0  \n",
      "12            0.0  \n",
      "15            0.0  \n",
      "22            0.0  \n",
      "30            0.0  \n",
      "...           ...  \n",
      "282284        0.0  \n",
      "282292        0.0  \n",
      "282302        0.0  \n",
      "282308        0.0  \n",
      "282316        0.0  \n",
      "\n",
      "[282317 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# รวม energy & temperature\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "#read files\n",
    "df1 = pd.read_csv(r\"E:\\Sort Data\\cham4_mix\\cham4_energy&temp&humidity_4.csv\")  #<<<<<<<<<<<<<<\n",
    "df2 = pd.read_csv(r\"E:\\Sort Data\\cham4_intensity\\cham4_intensity_4.csv\")  #<<<<<<<<<<<<<<\n",
    "\n",
    "# Convert 'time' columns to datetime objects for both DataFrames\n",
    "df1['time'] = pd.to_datetime(df1['time'])\n",
    "df2['time'] = pd.to_datetime(df2['time'])\n",
    "\n",
    "# Sort both DataFrames by 'time'\n",
    "df1 = df1.sort_values(by='time')\n",
    "df2 = df2.sort_values(by='time')\n",
    "\n",
    "# Merge the two DataFrames based on 'time' and 'id_floor' using merge_asof\n",
    "result = pd.merge_asof(df1, df2, on='time', by='id_floor', direction='forward', tolerance=pd.Timedelta('5 minutes'))\n",
    "\n",
    "#sort\n",
    "result = result.sort_values(by=['id_floor','time'])\n",
    "\n",
    "print(result)\n",
    "\n",
    "result.to_csv(r\"E:\\Sort Data\\cham4_4variable_4.csv\", index=False)  #<<<<<<<<<<<<<<"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of empty energy values: 0\n",
      "Number of empty temperature values: 507\n",
      "Number of empty humidity values: 507\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "a=r\"E:\\Sort Data\\cham4_energy&temp&humidity_1.csv\"\n",
    "\n",
    "df = pd.read_csv(a)\n",
    "\n",
    "#df = df.sort_values(by=['id_floor','time'])\n",
    "\n",
    "# df.rename(columns={'value': 'energy'}, inplace=True)\n",
    "# df.rename(columns={'id_group': 'id_floor'}, inplace=True)\n",
    "\n",
    "# Count the number of empty energy and temperature values\n",
    "num_empty_energy = df['energy'].isnull().sum()\n",
    "num_empty_temperature = df['temperature'].isnull().sum()\n",
    "num_empty_humidity = df['humidity'].isnull().sum()\n",
    "\n",
    "print(f\"Number of empty energy values: {num_empty_energy}\")\n",
    "print(f\"Number of empty temperature values: {num_empty_temperature}\")\n",
    "print(f\"Number of empty humidity values: {num_empty_humidity}\")\n",
    "\n",
    "#df.to_csv(a, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading files: 100%|██████████| 732/732 [00:59<00:00, 12.21file/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "def read_files_in_fraction(directory_path, fraction_start, fraction_end):\n",
    "    # Get a list of file names in the directory\n",
    "    file_names = os.listdir(directory_path)\n",
    "\n",
    "    # Calculate the number of files to read based on the fraction\n",
    "    num_files_to_read_start = int(len(file_names) * fraction_start)\n",
    "    num_files_to_read_end = int(len(file_names) * fraction_end)\n",
    "\n",
    "    # Initialize an empty list to store individual DataFrames\n",
    "    dataframes = []\n",
    "\n",
    "    # Use tqdm to create a progress bar for reading files\n",
    "    for file_name in tqdm(file_names[num_files_to_read_start:num_files_to_read_end], desc=\"Reading files\", unit=\"file\"):\n",
    "        if file_name.endswith('.csv'):  # Adjust the file extension based on your files (e.g., .csv, .xlsx, etc.)\n",
    "            file_path = os.path.join(directory_path, file_name)\n",
    "            df2 = pd.read_csv(file_path)  # Replace 'read_csv' with 'read_excel' for Excel files\n",
    "            dataframes.append(df2)\n",
    "\n",
    "    # Concatenate all the individual DataFrames into a single DataFrame\n",
    "    df3 = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "    return df3\n",
    "\n",
    "# Replace 'directory_path' with the path to the directory containing your files\n",
    "directory_path = 'E:\\\\CUSC Datalake\\\\cham4'  #<<<<<<<<<<<<<\n",
    "\n",
    "# Read 1/4 of the files\n",
    "df = read_files_in_fraction(directory_path, 0, 0.25)  #<<<<<<<<<<<<<\n",
    "\n",
    "df = df[df['id'].str.contains('intensity')]\n",
    "\n",
    "df['id_floor'] = df['id'].str.extract(r'(fl(?:m|\\d{1,2}[a-zA-Z]?))')\n",
    "\n",
    "df = df.sort_values(by=['id_floor','time'])\n",
    "\n",
    "df.to_csv(r\"E:\\Sort Data\\cham4_intensity_test.csv\", index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#หาไอดีไม่ซ้ำ\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "df = pd.read_csv(r\"E:\\Sort Data\\cham4_intensity\\cham4_intensity_1.csv\")\n",
    "\n",
    "#unique_id_column = df.drop_duplicates(subset='id')['id']\n",
    "\n",
    "df = df[df['intensity'] <= 10000]\n",
    "\n",
    "df.to_csv(r\"E:\\Sort Data\\cham4_intensity\\cham4_intensity_new1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
